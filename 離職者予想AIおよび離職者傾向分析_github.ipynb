{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#離職者予想AIおよび離職者傾向分析\n",
        "\n",
        "福井県立大学 生物資源学部 生物資源学科 2年\n",
        "\n",
        "高﨑仁美"
      ],
      "metadata": {
        "id": "o9pXW4-pLOwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0 概要"
      ],
      "metadata": {
        "id": "rcwMCKnItA5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 使用言語：python\n",
        "\n",
        "* 使用したツール：Google colab\n",
        "\n",
        "* 分析対象：Excelにて蓄積された従業員データ\n",
        "\n",
        "* 想定する使い方：会社の人事データからその人が離職しやすいかを予測する\n",
        "\n",
        "* 基本的な使い方：セルにマウスカーソルを合わせた際に出てくる再生ボタンを押すことでそのセルを実行することが可能"
      ],
      "metadata": {
        "id": "33We0jqFl_Dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 注意事項"
      ],
      "metadata": {
        "id": "DLk6ZUEotoE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   セル結合がなされたデータは使用できません。結合を解除し、データを埋めてからお使いください。\n",
        "2.   元のExcelのデータは必ずカラム名が1行目、データ自体はA2から始まるよう調節をお願いします。\n",
        "3.   想定外のバグにつながりますので、必ず順番通り・指示通りに実行するようお願いします。\n",
        "4.   目的変数 (ここでいう離職したかしていないか) のデータは欠損がないようお願いします。"
      ],
      "metadata": {
        "id": "55y6gzzkJQrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用するデータセットに関して"
      ],
      "metadata": {
        "id": "ev9YQcVYs2IJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPP4yBlvMjqW"
      },
      "source": [
        "今回は例として以下のサイトからデータを拝借いたしました。\n",
        "https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset/discussion/86957\n",
        "\n",
        "\n",
        "実用化される時を想定し、[Googleフォーム](https://forms.gle/QMokMW2EyEJGZJcd6)にてテンプレートを作成いたしました。以下の指示に従って実装してください。\n",
        "\n",
        "1.   フォームに回答する\n",
        "2.   回答結果をスプレッドシートにて確認\n",
        "3.   スプレッドシートをExcelにする\n",
        "4.   新しくカラムを追加し、離職したかしていないかを記載\n",
        "5.   機械学習に導入\n",
        "\n",
        "  詳しい導入方法は軽いデータの可視化を参照してください\n",
        "スプレッドシートをExcelにして導入してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N-ku94tVnTn"
      },
      "source": [
        "## 1 データの可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 データの導入"
      ],
      "metadata": {
        "id": "WsCOtNmvikzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiBg4T0rMfcm"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをimport\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1vVZq2kZDVZ"
      },
      "outputs": [],
      "source": [
        "#最大表示行数の指定\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行するにあたり、Googleアカウントへのアクセスが求められます。以下の指示に従い、処理を行ってください。\n",
        "\n",
        "\n",
        "\n",
        "1.   以下のコードを実行する\n",
        "2.   「このノートブックにGoogle ドライブのファイルへのアクセスを許可しますか？」というウィンドウが出てくるので、「Google ドライブに接続」をクリック\n",
        "3.   アカウントを選択する画面が出てくるので、任意のアカウントを選択する\n",
        "4.   「Google Drive for desktopにログイン」という画面が出てくるので、次へをクリック\n",
        "5.   「Google Drive for desktopがGoogle アカウントへの追加アクセスを求めています」という画面が出てくるので、続行をクリック\n",
        "\n",
        "  (この時、選択したGoogle アカウントのGmailに「Googleからお使いのGoogle アカウントへのアクセスがGoogle Drive for desktopに許可されました」という文言が書かれたメールを受け取ることになる)\n",
        "\n"
      ],
      "metadata": {
        "id": "2GLVwzICoVxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvLzqwEVZJJw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルのコードは人によって異なります。以下の指示に従ってコードを各自書き換えてください。\n",
        "\n",
        "1.   添付したExcelのデータセットをGoogleドライブに入れる\n",
        "2.  左側に表示されている以下のマークをクリックし、1で導入したファイルを探す\n",
        "\n",
        "    ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACsAAAAvCAYAAAB6zDPWAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAE5SURBVGhD7dkxaoVAEIDhSWqxU2y8gKAXEUSwtdULeA4voK2tIIIXUfACNqKd2CcZWQgBs/GRHUGYr3nuNvsj88THe/v4Ag/xLj4fgWOpcCwVjqXCsVQ4lsqf7wbjOEJVVTDPs9j5nWmakGUZGIYhdtSS3tlpmqAoikuhaFkWyPMc1nUVO2pJY/u+h23bxOoaymDpGLRtC03THNdhGEIQBMf1mWEYoCxL2Pdd7LzOsiyI4xgcxxE7Pyn7grmuC0mSgKZpYud1OG44djh+Z5Q+DVQE49jh+J1RNgb/deWsRz1nOZYKx1LhWCocS4VjqXAslUfFSl8Ru66Duq7F6j5RFIHv+2L1TXpnPc8DXdfF6h54Hp57Rhpr2zakaXr8NroDnoPn4bln+D8FKhxLhWOpcCwVjqXyoFiAT13wckFb2MErAAAAAElFTkSuQmCC)\n",
        "\n",
        "\n",
        "2.   三点リーダーをクリック\n",
        "3.   「パスをコピー」をクリックし、パスをコピーする\n",
        "4.  `df = pd.read_csv('`**ここにペースト**`')`"
      ],
      "metadata": {
        "id": "-gvjJ4lWrHzW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR1kAiNgZLEC"
      },
      "outputs": [],
      "source": [
        "# dataを読み込む\n",
        "df = pd.read_csv('/content/drive/MyDrive/福井ソフトウェアコンペティション/Attrition_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "きちんとデータが導入されたか確認するために一度データを表示させます。"
      ],
      "metadata": {
        "id": "0YWODyRZi13G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZc8CbpzZNnl"
      },
      "outputs": [],
      "source": [
        "# データの確認\n",
        "print(f\"df shape: {df.shape}\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これでデータが入ったことが確認できました。"
      ],
      "metadata": {
        "id": "1ce2I2_BjEu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 データをグラフにする"
      ],
      "metadata": {
        "id": "BcGQOB_rhzFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sweetvizというモジュールを使って全体のデータをグラフ化してみます。実行は時間がかかります。\n",
        "\n",
        "他のデータを扱う場合は以下のコードの部分を指示通りに書き換えてください。\n",
        "\n",
        "`eda = sv.analyze(df,target_feat=\"Attrition\")`\n",
        "\n",
        "`Attrition`の部分を任意の目的変数のカラム名に書き換える"
      ],
      "metadata": {
        "id": "u933df9QhzF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz\n",
        "\n",
        "import sweetviz as sv"
      ],
      "metadata": {
        "id": "xc9b4MnthzF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 目的変数の名前を入力する関数\n",
        "def input_target_variable():\n",
        "    target_variable = input(\"目的変数の名前を入力してください: \")\n",
        "    return target_variable\n",
        "\n",
        "# ユーザーから目的変数を取得\n",
        "target_variable = input_target_variable()\n",
        "\n",
        "# 選択された目的変数を表示\n",
        "print(f\"目的変数は: {target_variable}\")\n"
      ],
      "metadata": {
        "id": "E2dydG_xeAvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df を分析するために sweetviz を使用\n",
        "eda = sv.analyze(df)\n",
        "\n",
        "# Data というラベル付ける\n",
        "eda = sv.analyze([df, \"Data\"])"
      ],
      "metadata": {
        "id": "9-cfUz-FgGhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweetvizの結果を表示\n",
        "eda.show_notebook()"
      ],
      "metadata": {
        "id": "MyU4vWTdhzF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の情報をもとに列名を日本語に翻訳したものになります。\n",
        "\n",
        "|列| 名称（日本語） | 説明 |\n",
        "| --- | --- | --- |\n",
        "|Age| 年齢 | 数値 |\n",
        "|Attrision| 離職 | 文字列 - 従業員の退職 |\n",
        "|BusinessTravel|出張頻度 | 文字列 - 出張なし, 頻繁に出張, 稀に出張 |\n",
        "|DailyAchievement| 日間業績 | 数値 - 日間業績レベル |\n",
        "|Department| 部門 | 文字列 - 人事, 研究開発, 営業 |\n",
        "|DistanceFromHome| 自宅からの距離 | 数値 - 職場から自宅までの距離 |\n",
        "|Education| 教育 | 文字列 - カレッジ未満, カレッジ, 学士, 修士, 博士 |\n",
        "|EducationField| 教育分野 | 文字列 - 人事, 生命科学, マーケティング, 医学, その他, 技術 |\n",
        "|EmployeeCount| 従業員数 | 数値 |\n",
        "|EmployeeNumber| 従業員番号 | 数値 - 従業員ID |\n",
        "|EnvironmentSatisfaction| 環境満足度 | 文字列 - 低い, 中程度, 高い, 非常に高い |\n",
        "|Gender| 性別 | 文字列 - 女性, 男性 |\n",
        "|HourlyAchievement| 時間業績 | 数値 - 時間業績 |\n",
        "|JobInvolvement| 職務関与度 | 文字列 - 低い, 中程度, 高い, 非常に高い |\n",
        "|JobLevel| 職位 | 数値 - 職のレベル |\n",
        "|JobRole| 職務役割 | 文字列 - HC代表, 人事, ラボ技術者, マネージャー, 管理ディレクター, 研究ディレクター, 研究科学者, 営業エグゼクティブ, 営業担当 |\n",
        "|JobSatisfaction| 職務満足度 | 文字列 - 低い, 中程度, 高い, 非常に高い |\n",
        "|MaritalStatus| 婚姻状況 | 文字列 - 離婚, 既婚, 独身 |\n",
        "|MonthlyIncome| 月給 | 数値 - 月給 |\n",
        "|MonthlyAchievement| 月間業績 | 数値 - 月間業績 |\n",
        "|NumCompaniesWorked| 勤務した会社数 | 数値 - 勤めた会社の数 |\n",
        "|Over18| 18歳以上 | 文字列 - はい, いいえ |\n",
        "|OverTime| 残業 | 文字列 - いいえ, はい |\n",
        "|PercentSalaryHike| 給与増加率 | 数値 - 給与の増加率。2年間（2017年、2018年）の給与変動の割合 |\n",
        "|PerformanceRating| パフォーマンス評価 | 文字列 - 低い, 良い, 優秀, 非常に優秀 |\n",
        "|RelationshipSatisfaction| 関係満足度 | 文字列 - 低い, 中程度, 高い, 非常に高い |\n",
        "|StandardHours| 標準労働時間 | 数値 - 標準労働時間 |\n",
        "|StockOptionLevel| 株式オプションレベル | 数値 - 株式オプション。この会社の株式をどれだけ所有しているか |\n",
        "|TotalWorkingYears| 総勤務年数 | 数値 - 総勤務年数 |\n",
        "|TrainingTimesLastYear| 昨年の研修回数 | 数値 - 昨年の研修で費やした時間 |\n",
        "|WorkLifeBalance |ワークライフバランス | 文字列 - 悪い, 良い, より良い, 最良 |\n",
        "|YearsAtCompany |会社勤続年数 | 数値 - 会社での総勤務年数 |\n",
        "|YearsInCurrentRole| 現在の役割での年数 |数値 - 現在の役割での年数|\n",
        "|YearsSinceLastPromotion|最後の昇進からの年数|数値 - 最後の昇進からの年数|\n",
        "|YearsWithCurrManager|現在のマネージャーとの年数|数値 - 現在のマネージャーとの勤務年数|"
      ],
      "metadata": {
        "id": "hkm7XfoJoPQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語を数字に直したデータの可視化も行っておきます。実行理由は以下の二点です。\n",
        "\n",
        "\n",
        "\n",
        "1.   上記のコードでグラフを表示させたときに文字化けがあった場合のデータの可視化手段\n",
        "2.   データの可視化への利用\n",
        "\n",
        "\n",
        "何の数字が何を指名しているのかをもとのデータと照らし合わせて確認するようにしてください。\n",
        "\n",
        "ここではすべてラベルエンコーディングをしておきます。"
      ],
      "metadata": {
        "id": "E1wCarh0iKgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルの次の3つのセルを実行し、文字化けしていたら実行\n",
        "\n",
        "# LabelEncoderのインスタンスを作成\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 各カラムに対してラベルエンコーディングを実行\n",
        "df_eda = df.copy()  # 新しいDataFrameにコピーして変更を加える\n",
        "for column in df_eda.columns:\n",
        "    if df_eda[column].dtype == 'object':  # カテゴリカル変数のみ処理\n",
        "        df_eda[column] = label_encoder.fit_transform(df_eda[column])\n",
        "\n",
        "df_eda.head()"
      ],
      "metadata": {
        "id": "WYOmSZHgiKgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz\n",
        "\n",
        "import sweetviz as sv"
      ],
      "metadata": {
        "id": "sIZzbSOdiKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda = sv.analyze(df_eda)\n",
        "\n",
        "eda = sv.analyze([df_eda, \"Data\"])"
      ],
      "metadata": {
        "id": "UM29d-hHiKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eda.show_notebook()"
      ],
      "metadata": {
        "id": "k_3bxkm1iKgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の処理を行った場合は以下のような形にデータになります。\n",
        "\n",
        "|列| 名称（日本語） | 説明 |\n",
        "| --- | --- | --- |\n",
        "|Age| 年齢 | 数値 |\n",
        "|Attrision| 離職 | 従業員の退職（0=いいえ, 1=はい） |\n",
        "|BusinessTravel|出張頻度 | (1=出張なし, 2=頻繁に出張, 3=稀に出張) |\n",
        "|DailyAchievement| 日間業績 | 数値 - 日間業績レベル |\n",
        "|Department| 部門 | (1=人事, 2=研究開発, 3=営業) |\n",
        "|DistanceFromHome| 自宅からの距離 | 数値 - 職場から自宅までの距離 |\n",
        "|Education| 教育 | (1=カレッジ未満, 2=カレッジ, 3=学士, 4=修士, 5=博士) |\n",
        "|EducationField| 教育分野 | (1=人事, 2=生命科学, 3=マーケティング, 4=医学, 5=その他, 6=技術) |\n",
        "|EmployeeCount| 従業員数 | 数値 |\n",
        "|EmployeeNumber| 従業員番号 | 数値 - 従業員ID |\n",
        "|EnvironmentSatisfaction| 環境満足度 | (1=低い, 2=中程度, 3=高い, 4=非常に高い) |\n",
        "|Gender| 性別 | (1=女性, 2=男性) |\n",
        "|HourlyAchievement| 時間業績 | 数値 - 時間業績 |\n",
        "|JobInvolvement| 職務関与度 | (1=低い, 2=中程度, 3=高い, 4=非常に高い) |\n",
        "|JobLevel| 職位 | 数値 - 職のレベル |\n",
        "|JobRole| 職務役割 | (1=HC代表, 2=人事, 3=ラボ技術者, 4=マネージャー, 5=管理ディレクター, 6=研究ディレクター, 7=研究科学者, 8=営業エグゼクティブ, 9=営業担当) |\n",
        "|JobSatisfaction| 職務満足度 | (1=低い, 2=中程度, 3=高い, 4=非常に高い) |\n",
        "|MaritalStatus| 婚姻状況 | (1=離婚, 2=既婚, 3=独身) |\n",
        "|MonthlyIncome| 月給 | 数値 - 月給 |\n",
        "|MonthlyAchievement| 月間業績 | 数値 - 月間業績 |\n",
        "|NumCompaniesWorked| 勤務した会社数 | 数値 - 勤めた会社の数 |\n",
        "|Over18| 18歳以上 | (1=はい, 2=いいえ) |\n",
        "|OverTime| 残業 | (1=いいえ, 2=はい) |\n",
        "|PercentSalaryHike| 給与増加率 | 数値 - 給与の増加率。2年間（2017年、2018年）の給与変動の割合 |\n",
        "|PerformanceRating| パフォーマンス評価 | (1=低い, 2=良い, 3=優秀, 4=非常に優秀) |\n",
        "|RelationshipSatisfaction| 関係満足度 | (1=低い, 2=中程度, 3=高い, 4=非常に高い) |\n",
        "|StandardHours| 標準労働時間 | 数値 - 標準労働時間 |\n",
        "|StockOptionLevel| 株式オプションレベル | 数値 - 株式オプション。この会社の株式をどれだけ所有しているか |\n",
        "|TotalWorkingYears| 総勤務年数 | 数値 - 総勤務年数 |\n",
        "|TrainingTimesLastYear| 昨年の研修回数 | 数値 - 昨年の研修で費やした時間 |\n",
        "|WorkLifeBalance |ワークライフバランス | (1=悪い, 2=良い, 3=より良い, 4=最良) |\n",
        "|YearsAtCompany |会社勤続年数 | 数値 - 会社での総勤務年数 |\n",
        "|YearsInCurrentRole| 現在の役割での年数 |数値 - 現在の役割での年数|\n",
        "|YearsSinceLastPromotion|最後の昇進からの年数|数値 - 最後の昇進からの年数|\n",
        "|YearsWithCurrManager|現在のマネージャーとの年数|数値 - 現在のマネージャーとの勤務年数|"
      ],
      "metadata": {
        "id": "PwaGQRFKptSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3 データの中身の把握"
      ],
      "metadata": {
        "id": "FbHsTd1Cjds5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの持つ情報を確認します。\n",
        "何のカラムがいくつあるか、数列か文字列型かを見ることができます。"
      ],
      "metadata": {
        "id": "3XYVtUYi5npA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "RUPAohvO5hhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "基本統計量を見てみます。\n",
        "\n",
        "ここで大体のデータの傾向を確認します。\n",
        "\n",
        "*   数\n",
        "*   平均\n",
        "*   標準偏差\n",
        "*   最小値\n",
        "*   第一四分位数\n",
        "*   中央値\n",
        "*   第三四分位数\n",
        "*   最大値\n",
        "\n"
      ],
      "metadata": {
        "id": "QgB6SXD56LWB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzZPobtyaa0B"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "この後データの前処理を行うのですが、その際、任意のデータにどのような処理が必要なのかをグラフや上の表で確認します。主な確認事項は以下の通りです。\n",
        "\n",
        "* count：欠損値の有無の確認\n",
        "* min や max：外れ値の確認 (mean や 第一四分位数、中央値。第三四分位数と比較しながら、あまりに値が離れていることがあれば外れ値としてカウントします)"
      ],
      "metadata": {
        "id": "7n8fNyXnVAte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 データの前処理"
      ],
      "metadata": {
        "id": "Xf05_IwCnKwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 表記の揺れの統一"
      ],
      "metadata": {
        "id": "SLeCG-K3sJ8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自由表記の場合、人によって表記の仕方が違う場合があります。それら表記の揺れをここで正規化し、同一の表記として扱えるようにします。\n",
        "\n",
        "同一の表記として扱われる例としては、以下のようなものが挙げられます。\n",
        "\n",
        "* 全角と半角の混在: \"１２３\" と \"123\"  、\"ＡＢＣ\" と \"ABC\"\n",
        "* カタカナ表記揺れ: \"ｶﾀｶﾅ\" と \"カタカナ\"\n",
        "* 日本語の正規化: \"ﾃｽﾄ\" と \"テスト\"\n",
        "\n",
        "※このデータでは実行の必要がないため、以下二つのセルは実行しないようお願いします。実行した場合は画面上の「ランタイム」ボタンから「ランタイムを再接続する」をクリックし、初めからコードを実行しなおしてください。"
      ],
      "metadata": {
        "id": "miEClrnWnWfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neologdn"
      ],
      "metadata": {
        "id": "N_CeHO_2or59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neologdn\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    # 文字列型の場合のみ正規化\n",
        "    if isinstance(text, str):\n",
        "        # 日本語テキストの正規化\n",
        "        normalized_text = neologdn.normalize(text)\n",
        "        # 全角英数字を半角英数字に変換\n",
        "        normalized_text = ''.join([unicodedata.normalize('NFKC', char) if char.isnumeric() else char for char in normalized_text])\n",
        "        return normalized_text\n",
        "    else:\n",
        "        # 文字列型でない場合はそのまま返す\n",
        "        return text\n",
        "\n",
        "# データフレームの各要素に関数を適用\n",
        "df = df.applymap(normalize_text)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yaalVsD0ndkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 外れ値の処理"
      ],
      "metadata": {
        "id": "hfSP_7WKsYg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの中にある異常な値を処理します。外れ値を含んで機械学習を行いたい場合は飛ばしてください。今回は外れ値を除去する方法と欠損値として扱うコードを紹介します。外れ値の処理に関してはいくつか方法があるため、用途に応じて使い分けてください。\n",
        "\n",
        "使い方は以下の通りです。\n",
        "\n",
        "`column_name`を任意のカラム名に書き換えてください。\n",
        "\n",
        "※このデータでは実行の必要がないため、以下4 つのセルは実行しないようお願いします。実行した場合は画面上の「ランタイム」ボタンから「ランタイムを再接続する」をクリックし、初めからコードを実行しなおしてください。"
      ],
      "metadata": {
        "id": "yl-4V-QCqhL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは外れ値を含んだカラムごと除去するコードを紹介します。"
      ],
      "metadata": {
        "id": "hbQb2HseuS2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**閾値による外れ値の除去**\n",
        "\n",
        "ある閾値を設定し、その閾値を超える外れ値を除外する方法です。\n",
        "\n",
        "ここでは平均値±2標準偏差以内のデータを正常範囲として、それを超えるデータを外れ値と見なすことにします。"
      ],
      "metadata": {
        "id": "x-xWBezJrW0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = df['column_name'].mean()\n",
        "std_value = df['column_name'].std()\n",
        "threshold = 2\n",
        "\n",
        "df = df[(df['column_name'] >= mean_value - threshold * std_value) & (df['column_name'] <= mean_value + threshold * std_value)]"
      ],
      "metadata": {
        "id": "9lrVv7wxrp7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**四分位範囲を用いた外れ値の除去**\n",
        "\n",
        "データの中央50%に対する範囲を用いて外れ値を検出し、それを除外する方法です。四分位範囲を1.5倍に拡大し、そこから外れる値を外れ値とします。"
      ],
      "metadata": {
        "id": "M7-9g74jsj-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['column_name'].quantile(0.25)\n",
        "Q3 = df['column_name'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "df = df[(df['column_name'] >= Q1 - 1.5 * IQR) & (df['column_name'] <= Q3 + 1.5 * IQR)]"
      ],
      "metadata": {
        "id": "7B-b9Nb2tm0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に外れ値を欠損値として置き換える方法を紹介します。この方法を採用する場合、のちに出てくる「欠損値の補完」を行ってください。"
      ],
      "metadata": {
        "id": "tHESYBNOu032"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**閾値を設定し、外れ値を欠損値に置き換える**\n",
        "\n",
        "ある閾値を設定し、その閾値を超える外れ値を欠損値に置き換える方法です。\n",
        "\n",
        "ここでは平均値±2標準偏差以内のデータを正常範囲として、それを超えるデータを外れ値と見なすことにします。"
      ],
      "metadata": {
        "id": "CYJ_HRB3w79E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = df['column_name'].mean()\n",
        "std_value = df['column_name'].std()\n",
        "threshold = 2\n",
        "\n",
        "df['column_name'][(df['column_name'] < mean_value - threshold * std_value) | (df['column_name'] > mean_value + threshold * std_value)] = np.nan"
      ],
      "metadata": {
        "id": "xq3LLlOYwq7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**四分位範囲を用いて外れ値を欠損値に置き換える**\n",
        "\n",
        "データの中央50%に対する範囲を用いて外れ値を検出し、それを欠損値に置き換える方法です。四分位範囲を1.5倍に拡大し、そこから外れる値を外れ値とします。"
      ],
      "metadata": {
        "id": "fvoGjVVrvmeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['column_name'].quantile(0.25)\n",
        "Q3 = df['column_name'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "df['column_name'][(df['column_name'] < Q1 - 1.5 * IQR) | (df['column_name'] > Q3 + 1.5 * IQR)] = np.nan"
      ],
      "metadata": {
        "id": "HQ1Jo4bDmjbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 データの成型"
      ],
      "metadata": {
        "id": "tHtyEKGxvOHf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1C56g55m3DB"
      },
      "source": [
        "まずはカラムを確認します。ここでは変形する必要があるデータについて確認します。機械学習では文字列で表記されているデータは読み込むことができません。そのため、何のデータが文字列型なのかを確認し、数値に変換する必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは文字列で表記されているデータを確認します。"
      ],
      "metadata": {
        "id": "NUGPXklYvYRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY_CrXu0m3iz"
      },
      "outputs": [],
      "source": [
        "df.select_dtypes(include=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm4YETJXnKWk"
      },
      "source": [
        "このデータでは文字列型で表記されたカラムが9個あることがわかりました。\n",
        "\n",
        "それぞれのカラムの要素や要素数を調べてみます。\n",
        "\n",
        "他のデータに当てはめる場合に関しては以下を参考にデータを確認してみてください。\n",
        "\n",
        "\n",
        "\n",
        "1.   下のセルを以下のコードに書き換える\n",
        "\n",
        "  `df['column_name'].value_counts()`\n",
        "\n",
        "\n",
        "2.   `column_name`と書いてある部分に上の表の一番上に書かれたカラム名を記入する。\n",
        "\n",
        "複数のカラムが文字列型で表記されている場合は1,2を任意の個数分繰り返してください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJIjRCn8eirN"
      },
      "outputs": [],
      "source": [
        "# BusinessTravel：出張\n",
        "df['BusinessTravel'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLVBGcTzft2-"
      },
      "outputs": [],
      "source": [
        "# Department：部門\n",
        "df['Department'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFkeS4_YgH75"
      },
      "outputs": [],
      "source": [
        "# EducationField：大学の学部\n",
        "df['EducationField'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCcWAT10gcT7"
      },
      "outputs": [],
      "source": [
        "# Gender\n",
        "df['Gender'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ZplFvMg50P"
      },
      "outputs": [],
      "source": [
        "# JobRole：役職\n",
        "df['JobRole'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DpkmpwGhfIO"
      },
      "outputs": [],
      "source": [
        "# MaritalStatus：結婚してるか\n",
        "df['MaritalStatus'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X48IytDGjXNP"
      },
      "outputs": [],
      "source": [
        "# Over18：結婚してるか\n",
        "df['Over18'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPCjExEHjeVc"
      },
      "outputs": [],
      "source": [
        "# OverTime：結婚してるか\n",
        "df['OverTime'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**不必要なデータの削除**\n",
        "\n",
        "値が一つしかないものについてデータを見てみます。"
      ],
      "metadata": {
        "id": "leM-ucpA92kM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGZFGxzLhP2r"
      },
      "outputs": [],
      "source": [
        "# 月収\n",
        "df['EmployeeCount'].value_counts().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHiu4I7-hWkw"
      },
      "outputs": [],
      "source": [
        "# 18歳以上か\n",
        "df['Over18'].value_counts().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRIS_duhhaCU"
      },
      "outputs": [],
      "source": [
        "# 標準時間\n",
        "df['StandardHours'].value_counts().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FaoWy7WhlG7"
      },
      "source": [
        "値が一つしかなかった理由はエラーではなく、本当にこの値しか存在しないことがわかりました。\n",
        "\n",
        "機械学習を少しでも早く行うためにこの必要のないデータは削除することにします。削除せずに行っても問題ありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKnH9SwLhj07"
      },
      "outputs": [],
      "source": [
        "missing_list = ['EmployeeCount','Over18' , 'StandardHours']\n",
        "\n",
        "df.drop(missing_list, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# オブジェクト型のカラムを特定する\n",
        "object_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# エンコーダーを初期化する\n",
        "label_encoder = LabelEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "\n",
        "# 変換情報を保持するリストを初期化する\n",
        "transformations = []\n",
        "\n",
        "# 各オブジェクト型のカラムを処理する\n",
        "for col in object_columns:\n",
        "    unique_values = df[col].nunique()\n",
        "    if unique_values == 2:\n",
        "        # ラベルエンコーディングを適用する\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "        # 変換マッピングを記録する\n",
        "        mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "        transformations.append({'Column': col, 'Type': 'Label Encoding', 'Mapping': mapping})\n",
        "    elif unique_values > 2:\n",
        "        # ワンホットエンコーディングを適用する\n",
        "        encoded_cols = pd.DataFrame(onehot_encoder.fit_transform(df[[col]]))\n",
        "        encoded_cols.columns = onehot_encoder.get_feature_names_out([col])\n",
        "        df = df.drop(columns=[col])\n",
        "        df = pd.concat([df, encoded_cols], axis=1)\n",
        "        # 新しいカラム名を記録する\n",
        "        new_columns = list(encoded_cols.columns)\n",
        "        transformations.append({'Column': col, 'Type': 'One-Hot Encoding', 'New Columns': new_columns})\n",
        "\n",
        "# 変換情報をわかりやすく表示する関数\n",
        "def display_transformations(transformations):\n",
        "    for transformation in transformations:\n",
        "        print(f\"カラム: {transformation['Column']}\")\n",
        "        print(f\"  変換タイプ: {transformation['Type']}\")\n",
        "        if transformation['Type'] == 'Label Encoding':\n",
        "            print(\"  マッピング:\")\n",
        "            for original, encoded in transformation['Mapping'].items():\n",
        "                print(f\"    {original} -> {encoded}\")\n",
        "        elif transformation['Type'] == 'One-Hot Encoding':\n",
        "            print(\"  新しいカラム名:\")\n",
        "            for new_col in transformation['New Columns']:\n",
        "                print(f\"    {new_col}\")\n",
        "        print()  # 空行を追加して見やすくする\n",
        "\n",
        "# 変換情報を表示する\n",
        "display_transformations(transformations)"
      ],
      "metadata": {
        "id": "CngQwaCmCO_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "値が一つしかないものを削除するコードを追加"
      ],
      "metadata": {
        "id": "APRNof9FRKSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# アップロードされたファイルからデータを読み込む\n",
        "file_path = '/mnt/data/Attrition_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# オブジェクト型のカラムを特定する\n",
        "object_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# エンコーダーを初期化する\n",
        "label_encoder = LabelEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "\n",
        "# 変換情報を保持するリストを初期化する\n",
        "transformations = []\n",
        "\n",
        "# 各オブジェクト型のカラムを処理する\n",
        "for col in object_columns:\n",
        "    unique_values = df[col].nunique()\n",
        "    if unique_values == 1:\n",
        "        # 値が一つしかないカラムを削除する\n",
        "        df = df.drop(columns=[col])\n",
        "        transformations.append({'Column': col, 'Type': 'Single Value', 'Action': 'Deleted'})\n",
        "    elif unique_values == 2:\n",
        "        # ラベルエンコーディングを適用する\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "        # 変換マッピングを記録する\n",
        "        mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "        transformations.append({'Column': col, 'Type': 'Label Encoding', 'Mapping': mapping})\n",
        "    elif unique_values > 2:\n",
        "        # ワンホットエンコーディングを適用する\n",
        "        encoded_cols = pd.DataFrame(onehot_encoder.fit_transform(df[[col]]))\n",
        "        encoded_cols.columns = onehot_encoder.get_feature_names_out([col])\n",
        "        df = df.drop(columns=[col])\n",
        "        df = pd.concat([df, encoded_cols], axis=1)\n",
        "        # 新しいカラム名を記録する\n",
        "        new_columns = list(encoded_cols.columns)\n",
        "        transformations.append({'Column': col, 'Type': 'One-Hot Encoding', 'New Columns': new_columns})\n",
        "\n",
        "# 変換情報をわかりやすく表示する関数\n",
        "def display_transformations(transformations):\n",
        "    for transformation in transformations:\n",
        "        print(f\"カラム: {transformation['Column']}\")\n",
        "        print(f\"  変換タイプ: {transformation['Type']}\")\n",
        "        if transformation['Type'] == 'Single Value':\n",
        "            print(f\"  アクション: {transformation['Action']}\")\n",
        "        elif transformation['Type'] == 'Label Encoding':\n",
        "            print(\"  マッピング:\")\n",
        "            for original, encoded in transformation['Mapping'].items():\n",
        "                print(f\"    {original} -> {encoded}\")\n",
        "        elif transformation['Type'] == 'One-Hot Encoding':\n",
        "            print(\"  新しいカラム名:\")\n",
        "            for new_col in transformation['New Columns']:\n",
        "                print(f\"    {new_col}\")\n",
        "        print()  # 空行を追加して見やすくする\n",
        "\n",
        "# 変換情報を表示する\n",
        "display_transformations(transformations)\n",
        "\n",
        "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Processed DataFrame\", dataframe=df)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "dXvetaWzRHT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LvheNBZfLQaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpMiF7Fg1jX"
      },
      "source": [
        "**ラベルエンコーディング**\n",
        "\n",
        "いよいよ文字列型で書かれた項目を数字に変換していきます。特徴量が2つしかないものにラベルエンコーディングを施します。\n",
        "\n",
        "他のデータに当てはめる場合に関しては以下を参考にデータを書き換えてください。\n",
        "\n",
        "下のセルを以下のコードに書き換える\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_label = df.copy()  \n",
        "\n",
        "###\n",
        "df_label['column_name'] = label_encoder.fit_transform(df_label['column_name'])\n",
        "###\n",
        "\n",
        "# 結果を表示\n",
        "df_label.head()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "column_nameと書いてある部分に上の表の一番上に書かれたカラム名を記入する (文字列型のもの)。\n",
        "複数のカラムが文字列型で表記されている場合は`df_label['column_name'] = label_encoder.fit_transform(df_label['column_name'])`をコピーし`###`で囲われた部分に任意の個数分ペーストし、上記の指示の通りにコードを書き換えてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIGfGhPLMC1E"
      },
      "outputs": [],
      "source": [
        "# LabelEncoderのインスタンスを作成\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "# 各カラムに対してラベルエンコーディングを実行\n",
        "df_label = df.copy()  # 新しいDataFrameにコピーして変更を加える\n",
        "df_label['Attrition'] = label_encoder.fit_transform(df_label['Attrition'])\n",
        "df_label['Gender'] = label_encoder.fit_transform(df_label['Gender'])\n",
        "df_label['OverTime'] = label_encoder.fit_transform(df_label['OverTime'])\n",
        "\n",
        "# 結果を表示\n",
        "df_label.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv79YqPVobTE"
      },
      "source": [
        "**one-hotエンコーディング**\n",
        "\n",
        "特徴量が3つ以上のものにone-hotエンコーディングを施します。\n",
        "\n",
        "新しくカラムを追加し、各行が元のデータの一つのカテゴリを表すようにします。選ばれたカテゴリに対応する列の値が1で、それ以外が0です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCyc30TVn9uB"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encodingの適用\n",
        "df_ohe = pd.get_dummies(df_label)\n",
        "\n",
        "# 適用結果の確認（最初の10件）\n",
        "df_ohe[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の処理でそれぞれの数字にあてはめられたものは何かを確認するようにしてください。基本的には上から順番に0か1の番号が振られているはずです。"
      ],
      "metadata": {
        "id": "E1BdU5b-Bd67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 欠損値補完"
      ],
      "metadata": {
        "id": "E8JsdyX3sivc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxR_YtkXrmvH"
      },
      "source": [
        "欠損値の確認をします。\n",
        "\n",
        "上記の基本統計量を求めた際にこのデータには欠損値がないことがわかっていますが、ほかのデータを用いたとき用に処理を確定させておきます。\n",
        "\n",
        "欠損値の多い順にソートし、割合も表示させます。\n",
        "\n",
        "もっと欠損データが見たい場合は最後の行の`missing_data.head()`を少し書き換えます (デフォルトでは 5 行表示されるようになっています)。書き方は以下の通りです。\n",
        "\n",
        "`missing_data.head(`ここに任意の半角数字を入力`)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N-O3jDzrmvb"
      },
      "outputs": [],
      "source": [
        "total = df.isnull().sum().sort_values(ascending = False)\n",
        "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
        "missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCD0ivdermve"
      },
      "source": [
        "欠損値の処理については様々な解釈があります。よってここでは複数の処理を実行できるよう、いくつかコードを提示しておきます。用途に応じて使用するコードを使い分けてください。\n",
        "\n",
        "※このデータでは実行の必要がないため、以下の欠損値に関する処理は実行しないようお願いします。実行した場合は画面上の「ランタイム」ボタンから「ランタイムを再接続する」をクリックし、初めからコードを実行しなおしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**欠損値削除**\n",
        "\n",
        "欠損している個所を削除します。通常はあまりお勧めできませんが、欠損している値が非常に多い場合などでは有効な手段となります。"
      ],
      "metadata": {
        "id": "hGnzxiUarmvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入方法\n",
        "\n",
        "1.   一行目のコードを書き換える。\n",
        "\n",
        "  `df.drop('`ここを任意のカラム名に変更する`', axis=1, inplace=True)`\n",
        "\n",
        "2.   複数ある場合は次のセルを複製してコードを任意のものに書き換える"
      ],
      "metadata": {
        "id": "ur0ewmCFrmvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('ここを任意のカラム名に変更する', axis=1, inplace=True)\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "G5BrLTabrmvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**平均値補完**\n",
        "\n",
        "欠損値を平均で補完します。処理が簡単なため、素早く補完することができます。欠損している部分が少ない場合など簡単な処理で済ませたい場合に有効な手段です。ただしデータに外れ値が存在する場合、平均値は外れ値に依存するため、有効な手段であるとは言えません。"
      ],
      "metadata": {
        "id": "O-Ibt4wTrmvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入方法\n",
        "\n",
        "1.   一行目と二行目のコードを書き換える。\n",
        "\n",
        "  a` = pd.concat(df['`AAAAA`'])`\n",
        "\n",
        "  `df['`AAAAA`'].fillna(`a`.mean(), inplace=True)`\n",
        "\n",
        "\n",
        "*   AAAAAについて\n",
        "\n",
        "  ここを任意のカラム名に変更する。\n",
        "\n",
        "  なお一行目と二行目の AAAAA は同じものにする。\n",
        "\n",
        "*   mean_value1について\n",
        "\n",
        "  複数ある場合、ほかのセルではmean_value2、mean_value3...のように数字を増やすなどして変数を変えるようにする。\n",
        "\n",
        "  なお一行目と二行目の a は同じものにする。\n",
        "\n",
        "2.   補完したいカラムが複数ある場合は次のセルを複製してコードを任意のものに書き換える\n",
        "\n"
      ],
      "metadata": {
        "id": "5zn7Xp3vrmvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value1 = pd.concat(df['AAAAA'])\n",
        "\n",
        "df['AAAAA'].fillna(mean_value1.mean(), inplace=True)\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "qQ3a2VwDrmvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**最頻値補完**\n",
        "\n",
        "欠損値を最頻値で補完します。処理が簡単なため、素早く補完することができます。欠損している部分が少ない場合など簡単な処理で済ませたい場合に有効な手段です。"
      ],
      "metadata": {
        "id": "ZOQd9m96rmvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入方法\n",
        "\n",
        "1.   一行目と二行目のコードを書き換える。\n",
        "\n",
        "  mode_value1` = df['`AAAAA`'].mode()[0]`\n",
        "\n",
        "  `df['`AAAAA`'].fillna(`mode_value1`, inplace=True)`\n",
        "\n",
        "\n",
        "*   AAAAAについて\n",
        "\n",
        "  ここを任意のカラム名に変更する。\n",
        "\n",
        "  なお一行目と二行目の AAAAA は同じものにする。\n",
        "\n",
        "*   mode_value1について\n",
        "\n",
        "  複数ある場合、ほかのセルではmode_value2、mode_value3...のように数字を増やすなどして変数を変えるようにする。\n",
        "\n",
        "  なお一行目と二行目の a は同じものにする。\n",
        "\n",
        "2.   補完したいカラムが複数ある場合は次のセルを複製してコードを任意のものに書き換える\n"
      ],
      "metadata": {
        "id": "OhI9QF-1rmvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AAAAA列の最頻値を計算\n",
        "mode_value1 = df['AAAAA'].mode()[0]\n",
        "\n",
        "# 欠損値を最頻値で補完\n",
        "df['AAAAA'].fillna(mode_value1, inplace=True)\n",
        "\n",
        "# 欠損値の確認\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "hlLFiQCkrmv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ランダムフォレストによる欠損値補完**\n",
        "\n",
        "機械学習法を用いて欠損値を補完します。今回はランダムフォレストという機械学習手法を採用します。全体の傾向をとらえ、欠損している値を補填する方法です。実行には時間がかかります。"
      ],
      "metadata": {
        "id": "8OFwZRhirmv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# IterativeImputerを用いてRandomForestRegressorで欠損値を補完\n",
        "imputer = IterativeImputer(estimator=RandomForestRegressor(), random_state=0)\n",
        "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FKqenye0rmv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNNによる欠損値補完**\n",
        "\n",
        "同じく機械学習を用いて欠損値を補完します。KNNという機械学習手法を採用します。上の補完方法は全体の特徴を考慮するものであったのに対し、こちらは欠損値があるサンプルの近くにあるサンプルを考慮して補完します。実行には時間がかかります。"
      ],
      "metadata": {
        "id": "Ja4-DB5prmv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=2)  # n_neighborsは近傍の数を指定\n",
        "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FQ7g7_wXrmv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLUyur4mki74"
      },
      "source": [
        "## 3 データの可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1ヒストグラムで全体を見る"
      ],
      "metadata": {
        "id": "MoW4kGEcduBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "先ほどすでに全体のヒストグラムは確認しましたが、データの成型を経てデータがどう変わったかグラフで見てみましょう。実行には時間がかかります。"
      ],
      "metadata": {
        "id": "lVQhu3S1uwu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sweetviz\n",
        "\n",
        "import sweetviz as sv"
      ],
      "metadata": {
        "id": "53wFfOi1vBzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = sv.analyze(df_ohe)\n",
        "\n",
        "report = sv.analyze([df_ohe, \"Data\"])"
      ],
      "metadata": {
        "id": "gP7mDZvfvGj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report.show_notebook()"
      ],
      "metadata": {
        "id": "rbJWR9TZvKdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 離職率との関係"
      ],
      "metadata": {
        "id": "3Y87zuzI43oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "離職率とほかの特徴の関係について見てみます。\n",
        "\n",
        "まずは本命であるAttrition(離職率)について見てみます。\n",
        "* 0 → No\n",
        "* 1 → Yes\n",
        "\n",
        "他のデータを用いる場合は以下のコードで`Attrition`と書かれているところを任意の目的変数のカラム名にしてください。"
      ],
      "metadata": {
        "id": "wdVBcu-AChhM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bjVwrgnrs6s"
      },
      "outputs": [],
      "source": [
        "# カテゴリのラベルを格納するリスト\n",
        "labels = ['No', 'Yes']\n",
        "\n",
        "# グラフのサイズを設定\n",
        "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# 円グラフ\n",
        "colors = ['#13538a', '#37c9ef']\n",
        "df_ohe['Attrition'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True, labels=labels,\n",
        "                                           textprops={'color': 'white', 'fontsize': 16}, colors=colors)\n",
        "ax[0].set_title('Attrition', {\"fontsize\": 20})\n",
        "ax[0].set_ylabel('')\n",
        "\n",
        "# 棒グラフ\n",
        "sns.countplot(x='Attrition', data=df_ohe, ax=ax[1], palette=colors)\n",
        "ax[1].set_title('Attrition', {\"fontsize\": 20})\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ヒートマップで全体の相関を確認してみます。"
      ],
      "metadata": {
        "id": "9fcTYiJrDuPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go4xUBL1Ru30"
      },
      "outputs": [],
      "source": [
        "corr=df_ohe.corr()\n",
        "sns.heatmap(corr, square=True, annot=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "目的変数であるAttrition (離職率) と相関係数が高いものを降順に表示させます"
      ],
      "metadata": {
        "id": "MPPssDvqEb-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k30E6aRrfc36"
      },
      "outputs": [],
      "source": [
        "# 'Attrition'と他の変数の相関行列を計算\n",
        "correlation_matrix = df_ohe.corr()\n",
        "\n",
        "# 'Attrition'との相関を表示\n",
        "attrition_correlation = correlation_matrix['Attrition']\n",
        "\n",
        "# 相関が大きい順にソートして表示\n",
        "sorted_attrition_correlation = attrition_correlation.abs().sort_values(ascending=False)\n",
        "\n",
        "sorted_attrition_correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 相関係数の結果から個別にデータを見る"
      ],
      "metadata": {
        "id": "eVBkPRfC5Sap"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-lqfaKWmdhc"
      },
      "source": [
        "相関係数が高い項目について離職した人と離職していない人に分けて個別にみてみます。ここでは離職者の傾向を分析することができます。気になった項目についてもここで確認してみましょう。まずは円グラフで表示できるものについてです。\n",
        "\n",
        "他のデータに当てはめる場合に関しては以下を参考にデータを確認してみてください。\n",
        "\n",
        "\n",
        "\n",
        "1.   下のセルを以下のコードに書き換える\n",
        "\n",
        "  \n",
        "```\n",
        "# グラフのサイズを設定\n",
        "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# 1行目の円グラフ\n",
        "colors1 = ['#13538a', '#37c9ef']\n",
        "df_ohe['Attrition'][df_ohe['column_name'] == 1].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[0].set_title('Attrition Rate (column_name_english=1)')\n",
        "\n",
        "# 2行目の円グラフ\n",
        "df_ohe['Attrition'][df_ohe['column_name'] == 0].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[1], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[1].set_title('Attrition Rate (column_name_english=0)')\n",
        "\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "2.   `Attrition`を任意の目的変数のカラム名にし、`column_name`と書いてある部分に任意のカラム名を記入する。\n",
        "\n",
        "3.   `column_name_english`と書いてある部分に任意のカラム名を英字で記入する。\n",
        "\n",
        "  ここで日本語を使ってはいけない理由は円グラフが日本語対応をしていないからです。カラムの名前を英語にするかローマ字で打つことをお勧めします。\n",
        "\n",
        "いくつか関係を見たい場合は1,2,3を任意の個数分繰り返してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* OverTime (残業時間) について\n",
        "\n",
        "  1 → 残業あり\n",
        "\n",
        "  0 → 残業なし\n",
        "\n",
        "  これにより残業をしている人のほうが離職率が高いことがわかります。"
      ],
      "metadata": {
        "id": "PHoywSqQFAA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCC5EynsbUmv"
      },
      "outputs": [],
      "source": [
        "# グラフのサイズを設定\n",
        "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# 1行目の円グラフ\n",
        "colors1 = ['#13538a', '#37c9ef']\n",
        "df_ohe['Attrition'][df_ohe['OverTime'] == 1].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[0].set_title('Attrition Rate (OverTime=1)')\n",
        "\n",
        "# 2行目の円グラフ\n",
        "df_ohe['Attrition'][df_ohe['OverTime'] == 0].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[1], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[1].set_title('Attrition Rate (OverTime=0)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MaritalStatus_Single (独身の人) について\n",
        "\n",
        "  1 → 独身の人\n",
        "  \n",
        "  0 → そうでない人\n",
        "\n",
        "  これにより独身の人のほうが離職率が高いことがわかります。"
      ],
      "metadata": {
        "id": "JdYdV1ZiFZxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzWNJShxIIOT"
      },
      "outputs": [],
      "source": [
        "# グラフのサイズを設定\n",
        "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# 1行目の円グラフ\n",
        "colors1 = ['#13538a', '#37c9ef']\n",
        "df_ohe['Attrition'][df_ohe['MaritalStatus_Single'] == 1].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[0].set_title('Attrition Rate (MaritalStatus_Single=1)')\n",
        "\n",
        "# 2行目の円グラフ\n",
        "df_ohe['Attrition'][df_ohe['MaritalStatus_Single'] == 0].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[1], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[1].set_title('Attrition Rate (MaritalStatus_Single=0)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TotalWorkingYears(総勤務年)について\n",
        "\n",
        "  1 → 1年\n",
        "\n",
        "  0 → それ以外\n",
        "\n",
        "  これにより総勤務年が一年の人の離職率が高いことがわかります。"
      ],
      "metadata": {
        "id": "WDnwkftRy2vs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iprMgXruIkcU"
      },
      "outputs": [],
      "source": [
        "# グラフのサイズを設定\n",
        "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# 1行目の円グラフ\n",
        "colors1 = ['#13538a', '#37c9ef']\n",
        "df_ohe['Attrition'][df_ohe['TotalWorkingYears'] == 1].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[0].set_title('Attrition Rate (TotalWorkingYears=1)')\n",
        "\n",
        "# 2行目の円グラフ\n",
        "df_ohe['Attrition'][df_ohe['TotalWorkingYears'] == 0].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[1], colors=colors1, textprops={'color': 'white', 'fontsize': 30})\n",
        "ax[1].set_title('Attrition Rate (TotalWorkingYears=0)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次にヒストグラムでデータを確認してみます。赤が離職した人、青が離職しなかった人です。他のデータに当てはめる場合に関しては以下を参考にデータを確認してみてください。\n",
        "\n",
        "\n",
        "\n",
        "1.   下のセルを以下のコードに書き換える\n",
        "\n",
        "  \n",
        "```\n",
        "df_ohe.groupby([\"Attrition\"])[\"column_name\"].plot.hist(bins=20, alpha=0.5, legend=True)\n",
        "```\n",
        "\n",
        "2.   `Attrition`を任意の目的変数のカラム名にし、`column_name`と書いてある部分に任意のカラム名を記入する。\n",
        "\n",
        "\n",
        "いくつか関係を見たい場合は1,2を任意の個数分繰り返してください"
      ],
      "metadata": {
        "id": "bcKZ56Tt2Iyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age(年齢)について"
      ],
      "metadata": {
        "id": "t6fdpaQ93mCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELDQUb4gyEnI"
      },
      "outputs": [],
      "source": [
        "# 年齢\n",
        "df_ohe.groupby([\"Attrition\"])[\"Age\"].plot.hist(bins=20, alpha=0.5, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JobInvolvement(仕事の重要度)について"
      ],
      "metadata": {
        "id": "T8SiKO2R4AAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgHcpprPNvgN"
      },
      "outputs": [],
      "source": [
        "# 仕事の重要度\n",
        "df_ohe.groupby([\"Attrition\"])[\"JobInvolvement\"].plot.hist(bins=20, alpha=0.5, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JobLevel(仕事のレベル)について"
      ],
      "metadata": {
        "id": "MiB7BoFo4HBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5k2RBxbONxe"
      },
      "outputs": [],
      "source": [
        "# 仕事レベル\n",
        "df_ohe.groupby([\"Attrition\"])[\"JobLevel\"].plot.hist(bins=20, alpha=0.5, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hotエンコーディングでデータを成型したものに関してはカラムが別のものになっているため、可視化してもわかりにくい時があります。そのようなときは先ほど一括でラベルエンコーディングを施したものを利用してデータの可視化の続きを行います。"
      ],
      "metadata": {
        "id": "LEQ-p1gl06E-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JobRole(仕事の役割)について\n",
        "\n",
        "  8の人が辞めやすいことがわかります。\n",
        "\n",
        "  (0=HC代表, 1=人事, 2=ラボ技術者, 3=マネージャー, 4=管理ディレクター, 5=研究ディレクター, 6=研究科学者, 7=営業管理職, 8=営業担当)"
      ],
      "metadata": {
        "id": "dhIU9AFH4QtH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkmmclJlQzoa"
      },
      "outputs": [],
      "source": [
        "# 役割\n",
        "df_eda.groupby([\"Attrition\"])[\"JobRole\"].plot.hist(bins=20, alpha=0.5, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* EnvironmentSatisfaction(環境満足度)について\n",
        "\n",
        "  値が低いほど辞めやすいことがわかります。\n",
        "\n",
        "  (1=低い, 2=中程度, 3=高い, 4=非常に高い)"
      ],
      "metadata": {
        "id": "L-mNXT1t55zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMg4UCBCRJRU"
      },
      "outputs": [],
      "source": [
        "# 環境満足度\n",
        "df_eda.groupby([\"Attrition\"])[\"EnvironmentSatisfaction\"].plot.hist(bins=20, alpha=0.5, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr_sRH2QnTWQ"
      },
      "source": [
        "## 4 機械学習"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 離職者の予測"
      ],
      "metadata": {
        "id": "GAQ3zZa3XkMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "いよいよ機械学習にはいります。今回はlightGBMという強力なモデルを使用し、学習を行っていきます。"
      ],
      "metadata": {
        "id": "OoVPC7vaXsPk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvAQu_9bcTcN"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import ensemble\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "他のデータを使用する場合、下のセルの`Attrition`の部分を任意の目的変数のカラム名に書き換えてください。"
      ],
      "metadata": {
        "id": "IDopEb3g8i7u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7hQ_5jbcGZz"
      },
      "outputs": [],
      "source": [
        "X = df_ohe.drop('Attrition',axis=1)\n",
        "y = df_ohe['Attrition'] # 目的変数\n",
        "# トレーニングデータ,テストデータの分割\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "グリッドサーチを行い、機械学習の精度を向上させます。実行には数十分ほどかかる場合がありますのでご注意ください。"
      ],
      "metadata": {
        "id": "8-b_oVmJ9Us6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-adoqeRerccV"
      },
      "outputs": [],
      "source": [
        "# ハイパーパラメータのすべての組み合わせでモデルを構築・検証\n",
        "scores = {}\n",
        "for learning_rate in np.logspace(-3, 0, num=4):\n",
        "    for max_depth in range(3, 10):\n",
        "        for binary in [True, False]:\n",
        "            for multiclass in ['ovr', 'multiclass']:\n",
        "                for num_iterations in [50, 100, 200]:\n",
        "                    for num_leaves in [31, 63, 127]:\n",
        "                        for verbosity in [0, 1, 2]:\n",
        "                            lgbm_model = lgb.LGBMClassifier(\n",
        "                                learning_rate=learning_rate,\n",
        "                                max_depth=max_depth,\n",
        "                                binary=binary,\n",
        "                                multiclass=multiclass,\n",
        "                                num_iterations=num_iterations,\n",
        "                                num_leaves=num_leaves,\n",
        "                                verbosity=verbosity\n",
        "                            )\n",
        "                            lgbm_model.fit(X_train, y_train)\n",
        "                            y_pred = lgbm_model.predict(X_valid)\n",
        "                            accuracy = accuracy_score(y_valid, y_pred)\n",
        "                            scores[(learning_rate, max_depth, binary, multiclass, num_iterations, num_leaves, verbosity)] = accuracy\n",
        "\n",
        "# 検証結果をscoresに格納\n",
        "scores = pd.Series(scores)\n",
        "\n",
        "# 表示\n",
        "print('ベストスコア:{:.2f}'.format(scores.max()))\n",
        "print('その時のパラメータ:', scores.idxmax())\n",
        "\n",
        "# ヒートマップを表示\n",
        "heatmap_data = scores.unstack().fillna(0)\n",
        "sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt='.2f', cbar=True)\n",
        "plt.xlabel('verbosity')\n",
        "plt.ylabel('num_leaves')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のコードの実行結果の一番下に「その時のパラメータ:(...)」で()の中に値が表示されているかと思います。その「その時のパラメータ」で書かれている値を順番に以下の指示の通りにコードの部分に当てはめてください。\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "best_learning_rate = 一つ目の値\n",
        "best_max_depth = 二つ目の値\n",
        "best_binary = 三つ目の文字列\n",
        "best_multiclass = 四つ目の文字列\n",
        "best_num_iterations = 五つ目の値\n",
        "best_num_leaves = 六つ目の値\n",
        "best_verbosity = 七つ目の値\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Qs2sqMen-6MJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU0DF1hvl6s9"
      },
      "outputs": [],
      "source": [
        "# データの読み込み\n",
        "X = df_ohe.drop('Attrition',axis=1)\n",
        "y = df_ohe['Attrition'] # 目的変数\n",
        "# トレーニングデータ,テストデータの分割\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=0.2, random_state=0)\n",
        "\n",
        "# ベストパラメータを使用してLightGBMモデルを構築\n",
        "best_learning_rate = 0.1\n",
        "best_max_depth = 7\n",
        "best_binary = True\n",
        "best_multiclass = 'ovr'\n",
        "best_num_iterations = 200\n",
        "best_num_leaves = 31\n",
        "best_verbosity = 0\n",
        "\n",
        "lgbm_model = lgb.LGBMClassifier(learning_rate=best_learning_rate,\n",
        "                                max_depth=best_max_depth,\n",
        "                                binary=best_binary,\n",
        "                                multiclass=best_multiclass,\n",
        "                                num_iterations = best_num_iterations,\n",
        "                                num_leaves=best_num_leaves,\n",
        "                                verbosity=best_verbosity)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# モデルを使って予測\n",
        "y_pred = lgbm_model.predict(X_valid)\n",
        "\n",
        "# 精度の評価\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "print('ベストパラメータを使用したモデルの精度: {:.2f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これでAUCスコアが0.88のモデルが完成しました。"
      ],
      "metadata": {
        "id": "pYvd8Yyy2sQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acNfMNr1nFJo"
      },
      "outputs": [],
      "source": [
        "df_y_pred = pd.DataFrame(y_pred)\n",
        "df_y_pred.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j81t-axZAMVa"
      },
      "outputs": [],
      "source": [
        "pred_pr =lgbm_model.predict_proba(X_valid)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "予測結果を表示させます。"
      ],
      "metadata": {
        "id": "NtlGSkN1VvBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7YzxP5o_l_-"
      },
      "outputs": [],
      "source": [
        "df_y_pred = pd.DataFrame(pred_pr, columns=['Attrition_pred'])\n",
        "df_y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "予測データをもとのデータに結合させてわかりやすくします。"
      ],
      "metadata": {
        "id": "XGAiCfGtOj_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 行方向に結合\n",
        "result_df = pd.concat([df, df_y_pred], axis=1)\n",
        "\n",
        "# 結果の表示\n",
        "result_df.head()"
      ],
      "metadata": {
        "id": "fAiQ44-9IIGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 予測結果を見る"
      ],
      "metadata": {
        "id": "rnzgAlP7X17O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "検索機能を追加してみました。\n",
        "\n",
        "＜使い方＞\n",
        "\n",
        "一行目の最後に数字が書いてあると思います。ここに任意のEmployeeNumberを入力してください。\n",
        "```\n",
        "df_search = result_df[result_df['EmployeeNumber'] == ここに任意のEmployeeNumberを入力]\n",
        "df_search\n",
        "```\n",
        "\n",
        "他のデータを使用する場合やほかの項目で検索したい場合は`EmployeeNumber`を任意のカラム名に書き換えてください。"
      ],
      "metadata": {
        "id": "gOtag-U1OYcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_search = result_df[result_df['EmployeeNumber'] == 1]\n",
        "df_search"
      ],
      "metadata": {
        "id": "vRnrou-rN2Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習のデータから辞めやすそうな人上位10人を算出しました。もっとデータが見たい場合は最後の行に変更を加えます。\n",
        "\n",
        "`sorted_data.head(`ここを任意の数字を変えてください`)`"
      ],
      "metadata": {
        "id": "trYYmcX4Rjgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data = result_df[result_df['Attrition'] == 'No']\n",
        "sorted_data = filtered_data.sort_values(by='Attrition_pred', ascending=False)\n",
        "sorted_data.head(10)"
      ],
      "metadata": {
        "id": "S9my2QZoRCnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 予測結果の見方"
      ],
      "metadata": {
        "id": "6w4tIS-HYBBC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S70v7BrS0ND"
      },
      "source": [
        "データをどうやって見るかを確認します。どのスコアからAttritionを0(離職しない可能性が高い)とみなすか、1(離職する可能性がある)とみなすかを箱ひげ図で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqcGnq_oUqlJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 予測確率をDataFrameにまとめる\n",
        "df_results = pd.DataFrame({'Attrition': y_valid, 'y_pred': pred_pr})\n",
        "\n",
        "# 箱ひげ図の作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Attrition', y='y_pred', data=df_results)\n",
        "plt.title('Boxplot of y_pred for Attrition=0 and Attrition=1')\n",
        "plt.xlabel('Attrition')\n",
        "plt.ylabel('y_pred')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ちょうどAttritionが0のときの第三四分位数あたりが離職するかしないかの分かれ目であることが読み取れます。\n",
        "\n",
        "その第三四分位数の値を見てみます。"
      ],
      "metadata": {
        "id": "2NZxAVaqYWZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRAuPllEPIxp"
      },
      "outputs": [],
      "source": [
        "# 第三四分位数（75パーセンタイル）を計算\n",
        "third_quartile = np.percentile(pred_pr, 75)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"第三四分位数:\", third_quartile)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これによりAttrition_predictionの値が0.026以上の場合は離職しやすく、0.026以下の場合は離職しにくいことがわかりました。\n",
        "\n",
        "先ほどAUCスコアでこのモデルの精度がある程度測れたかと思います。上記の結果をもとにより詳しくこのモデルが持っている精度を見てみます。ここでは混合行列を使って確かめてみます。"
      ],
      "metadata": {
        "id": "x_2rZwsjZpGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW8XEFmJRRb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 閾値を設定\n",
        "threshold = 0.026\n",
        "\n",
        "# 閾値未満の場合は0、閾値以上の場合は1に変換\n",
        "y_pred_binary = [0 if val < threshold else 1 for val in pred_pr]\n",
        "\n",
        "# 混同行列を作成\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred_binary)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"混同行列:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "偽陽性と真陰性に着目します。ここから離職する人の約63 %が検出できたことがわかります。ただし、実際には非離職者でも離職者と予測しているものが44件(全データの約15 %)あることがわかります。このことから、適宜ヒアリングなどを経て判断をする必要があることが示唆されます。"
      ],
      "metadata": {
        "id": "4hK_e7E0agKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWJ8aVN3Ds9X"
      },
      "outputs": [],
      "source": [
        "# NumPyの配列をPandasのSeriesに変換\n",
        "y_valid_series = pd.Series(y_valid)\n",
        "\n",
        "# クラスごとの割合を算出\n",
        "class_ratios = y_valid_series.value_counts(normalize=True)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"クラスごとの割合:\")\n",
        "print(class_ratios)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "最後に予測結果を含めた表をcsv形式でダウンロードできるようにします。"
      ],
      "metadata": {
        "id": "lBtrINSEba6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# csvファイルを作成\n",
        "result_df.to_csv('Attrition_prediction.csv',index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('Attrition_prediction.csv')"
      ],
      "metadata": {
        "id": "FR7APEkZSc2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rcwMCKnItA5l",
        "DLk6ZUEotoE6",
        "ev9YQcVYs2IJ",
        "WsCOtNmvikzt",
        "BcGQOB_rhzFy",
        "FbHsTd1Cjds5",
        "SLeCG-K3sJ8F",
        "hfSP_7WKsYg2",
        "tHtyEKGxvOHf",
        "E8JsdyX3sivc",
        "MoW4kGEcduBn",
        "3Y87zuzI43oM",
        "eVBkPRfC5Sap",
        "GAQ3zZa3XkMe",
        "rnzgAlP7X17O",
        "6w4tIS-HYBBC"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}